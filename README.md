
[Delta Lab](https://links.deltalab.ai/website) | [Twitter](https://links.deltalab.ai/twitter) | [LinkedIn](https://links.deltalab.ai/linkedin)

---

# Sequential Minimal Optimization (SMO)

- Omar Trejo
- November, 2015

This contains a poster I developed for a SMO presentation.

The main idea behind SMO is that it's more efficient to reach a optimal point
when optimizaing a function if you move the lowest number of constraints in the
problem at the same time (which is two). When following this approach you'll get
an optimization that requires many more iterations but arguably can be much
faster.

The research is based on:

- [Bottou & Lin - Support Vector Machine Solvers (2007)](https://www.csie.ntu.edu.tw/~cjlin/papers/bottou_lin.pdf)
- [Platt - Sequential Minimal Optimization, A Fast Algorithm for Training Support Vector Machine (1998)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf)
- [Back, Lanckriet & Jordan - Fast Kernel Learning using Sequential Minimal Optimization (2004)](http://www.di.ens.fr/~fbach/CSD-04-1307.pdf)

This repository is related to the [Mathematical and numerical methods repository](https://github.com/otrenav/mmn).

Any feedback is welcome!

---

> "We are the people we have been waiting for."
